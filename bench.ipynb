{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import json\n",
    "from argparse import ArgumentParser\n",
    "import multiprocessing as mp\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from utils import *\n",
    "from resnet import make_model\n",
    "\n",
    "from bench import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "DATA_PATH = \"./data\"\n",
    "OUTPUT_PATH = \"./\"\n",
    "CUDA_DEVICES = \"all\"\n",
    "\n",
    "if CUDA_DEVICES == \"all\":\n",
    "    cuda_devices = list(range(torch.cuda.device_count()))\n",
    "else:\n",
    "    cuda_devices = list(map(lambda x: int(x.strip()), CUDA_DEVICES.split(\",\")))\n",
    "\n",
    "print(\"Deep Learning Benchmark\")\n",
    "print(\"  CUDA:  \", torch.cuda.is_available())\n",
    "print(\"  CUDNN: \", torch.backends.cudnn.enabled)\n",
    "print(\"  #GPUs: \", torch.cuda.device_count())\n",
    "print(\"  GPUs selected: \", cuda_devices)\n",
    "print()\n",
    "\n",
    "print(\"CIFAR10 dataset\")\n",
    "download_time, untar_time = download_cifar10(DATA_PATH)\n",
    "print(\"  download time:\", round(download_time, 3))\n",
    "print(\"  untar time:\", round(untar_time, 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "if torch.cuda.device_count() and torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    model_list = [\"ResNet18\", \"ResNet152\"] \n",
    "\n",
    "    print(\"CIFAR10 benchmark (RAM->GPU data transfer)\")\n",
    "    for model_type in model_list:\n",
    "        print(\"[\" + model_type + \"]\")\n",
    "        for device in cuda_devices:\n",
    "            trn_loader = make_cifar10_dataset(DATA_PATH, BATCH_SIZE, distributed=False, num_workers=0)\n",
    "            model_time, n_batches = train_cnn_ram(model_type, trn_loader, device)\n",
    "\n",
    "            add_item(stats, \"ram_gpu\", \"cuda:\" + str(device), \n",
    "                     model_type, model_time, n_batches, BATCH_SIZE * n_batches)\n",
    "\n",
    "            print(\"  cuda:\" + str(device), model_time, \"sec / batch (\" + str(n_batches) + \" batches, \" + str(BATCH_SIZE * n_batches) + \" images)\")\n",
    "    print()\n",
    "\n",
    "    print(\"CIFAR10 benchmark (full+disk)\")\n",
    "    for model_type in model_list:\n",
    "        for num_workers in range(0, mp.cpu_count()):\n",
    "            print(\"[\" + model_type + \" #workers \", num_workers, \"]\", sep=\"\")\n",
    "            for device in cuda_devices:\n",
    "                trn_loader = make_cifar10_dataset(DATA_PATH, BATCH_SIZE, distributed=False, num_workers=num_workers)\n",
    "                model_time, n_batches = train_cnn_full(model_type, trn_loader, device)\n",
    "\n",
    "                add_item(stats, \"cifar\" + str(num_workers).zfill(2), \"cuda:\" + str(device), \n",
    "                         model_type, model_time, n_batches, BATCH_SIZE * n_batches)\n",
    "\n",
    "                print(\"  cuda:\" + str(device), model_time, \"sec / batch (\" + str(n_batches) + \" batches, \" + str(BATCH_SIZE * n_batches) + \" images)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(stats)\n",
    "df.sort_values(by=[\"benchmark\", \"model\", \"device\"], inplace=True)\n",
    "df.to_csv(OUTPUT_PATH + \"/logs.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
