{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FakeData\n",
    "import PIL\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from cnn import *\n",
    "import shutil\n",
    "\n",
    "# cifar - 32x32\n",
    "# dim128 - 128x128\n",
    "# imagenet - 256x256\n",
    "# dim512 - 512x512\n",
    "# dim1024 - 1024x1024\n",
    "\n",
    "def generate_dataset(size, key):\n",
    "    assert key in [\"cifar\", \"dim128\", \"imagenet\", \"dim512\", \"dim1024\"]\n",
    "    \n",
    "    num_classes = 10\n",
    "    image_sizes = {\"cifar\": (3,32,32), \n",
    "                   \"dim128\": (3,128,128), \n",
    "                   \"imagenet\": (3,256,256), \n",
    "                   \"dim512\": (3,512,512), \n",
    "                   \"dim1024\": (3,1024,1024)\n",
    "                  }\n",
    "    image_size = image_sizes[key]\n",
    "    \n",
    "    folder_name = \"data/\" + key\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    for i in range(num_classes):\n",
    "        os.makedirs(folder_name + \"/\" + str(i), exist_ok=True)\n",
    "    \n",
    "    dataset = FakeData(size=size, image_size=image_size, num_classes=num_classes)\n",
    "    \n",
    "    for img_i, (img, cls) in tqdm_notebook(zip(range(size), dataset), total=size):\n",
    "        img.save(folder_name + \"/\" + str(cls.item()) + \"/img\" + str(img_i) + \".png\", \"PNG\")\n",
    "        \n",
    "        \n",
    "def train_cnn_full(model_type, trn_loader, n_trials=5, device=\"cuda:0\"):\n",
    "    assert device != \"cpu\"\n",
    "    if type(device) is int:\n",
    "        device = \"cuda:\" + str(device)\n",
    "    model = make_model(model_type.lower()).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    trial_time = []\n",
    "    for i_trial in range(n_trials):\n",
    "        start = time.time()\n",
    "        for batch_i, (batch, labels) in enumerate(trn_loader):\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            preds = model(batch)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        end = time.time()\n",
    "        trial_time.append(round((end - start) / batch_i, 3))\n",
    "\n",
    "    batch_i += 1\n",
    "    return trial_time, batch_i\n",
    "\n",
    "\n",
    "def add_item(stats, bench, cuda, model, time, batches, images):\n",
    "    stats.append({})\n",
    "    stats[-1][\"benchmark\"] = bench\n",
    "    stats[-1][\"device\"] = cuda\n",
    "    stats[-1][\"model\"] = model\n",
    "    stats[-1][\"time\"] = time\n",
    "    stats[-1][\"batches\"] = batches\n",
    "    stats[-1][\"objects\"] = images\n",
    "    \n",
    "\n",
    "def make_cnn_dataset_resnet(data_path, batch_size, device, distributed=False, num_workers=0, transformations=True):\n",
    "    torch.cuda.device(device)\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ColorJitter(.25,.25,.25),\n",
    "        transforms.RandomRotation(2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    if transformations:\n",
    "        train_data = torchvision.datasets.ImageFolder(data_path, transform_train)\n",
    "    else:\n",
    "        train_data = torchvision.datasets.ImageFolder(data_path)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.005, 3.027, 3.187, 3.002, 3.221, 3.347, 3.051, 3.049, 2.92, 3.497]\n"
     ]
    }
   ],
   "source": [
    "# Classic fs\n",
    "\n",
    "stats = []\n",
    "\n",
    "key = \"dim1024\"\n",
    "dataset_size = 2000\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "model_type = \"resnet18\"\n",
    "\n",
    "# generate_dataset(dataset_size, key)\n",
    "\n",
    "trn_loader = make_cnn_dataset_resnet(\"data/\" + key, batch_size, \"cuda\", False, num_workers, True)\n",
    "model_time, n_batches = train_cnn_full(model_type, trn_loader, 10)\n",
    "# add_item(stats, key, \"cuda:0\", model_type, model_time, n_batches, batch_size * n_batches)\n",
    "\n",
    "# shutil.rmtree(\"data/\" + key)\n",
    "\n",
    "print(model_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.52'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "if torch.cuda.device_count() and torch.backends.cudnn.enabled:\n",
    "    model_list = [\"ResNet18\", \"ResNet152\"] \n",
    "\n",
    "    print(\"CIFAR10 benchmark (RAM->GPU data transfer)\")\n",
    "    for model_type in model_list:\n",
    "        print(\"[\" + model_type + \"]\")\n",
    "        for device in cuda_devices:\n",
    "            trn_loader = make_cifar10_dataset(DATA_PATH, BATCH_SIZE, distributed=False, num_workers=0)\n",
    "            model_time, n_batches = train_cnn_ram(model_type, trn_loader, device)\n",
    "\n",
    "            add_item(stats, \"ram_gpu\", \"cuda:\" + str(device), \n",
    "                     model_type, model_time, n_batches, BATCH_SIZE * n_batches)\n",
    "\n",
    "            print(\"  cuda:\" + str(device), model_time, \"sec / batch (\" + str(n_batches) + \" batches, \" + str(BATCH_SIZE * n_batches) + \" images)\")\n",
    "    print()\n",
    "\n",
    "    print(\"CIFAR10 benchmark (full+disk)\")\n",
    "    for model_type in model_list:\n",
    "        for num_workers in range(0, mp.cpu_count()):\n",
    "            print(\"[\" + model_type + \" #workers \", num_workers, \"]\", sep=\"\")\n",
    "            for device in cuda_devices:\n",
    "                trn_loader = make_cifar10_dataset(DATA_PATH, BATCH_SIZE, distributed=False, num_workers=num_workers)\n",
    "                model_time, n_batches = train_cnn_full(model_type, trn_loader, device)\n",
    "\n",
    "                add_item(stats, \"cifar\" + str(num_workers).zfill(2), \"cuda:\" + str(device), \n",
    "                         model_type, model_time, n_batches, BATCH_SIZE * n_batches)\n",
    "\n",
    "                print(\"  cuda:\" + str(device), model_time, \"sec / batch (\" + str(n_batches) + \" batches, \" + str(BATCH_SIZE * n_batches) + \" images)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(stats)\n",
    "df.sort_values(by=[\"benchmark\", \"model\", \"device\"], inplace=True)\n",
    "df.to_csv(OUTPUT_PATH + \"/logs.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
